/**
 * Project Name: machine
 * Module Name: grammar
 * Filename: tokenize.c.dep
 * Creator: Yaokai Liu
 * Create Date: 2024-08-31
 * Copyright (c) 2024 Yaokai Liu. All rights reserved.
 **/

#include "tokenize.h"
#include "Array.h"
#include "allocator.h"
#include "enum.h"
#include "terminal.h"
#include "tokens.gen.h"
#include <stdint.h>
#define lenof(str_literal) ((sizeof str_literal) - 1)

uint32_t strcmp_o(const char_t * const str1, const char_t * const str2) {
  uint32_t ndx = 0;
  for (; str1[ndx] == str2[ndx] && str1[ndx]; ndx++);
  return ndx;
}

typedef struct {
  char_t left;
  char_t right;
} Range;

inline uint32_t match_single_char(const char_t *input, const char_t _the_char) {
  return (input[0] == _the_char);
}

inline uint32_t match_single_range(const char_t *input, const Range _the_range) {
  return (_the_range.left <= input[0] && input[0] <= _the_range.right);
}

inline uint32_t match_sequence(const char_t *input, const char_t *_the_seq, const uint32_t _seq_len) {
  return (strcmp_o(input, _the_seq) == _seq_len) * _seq_len;
}

inline uint32_t match_plain(const char_t *input, const char_t _the_seq[], const uint32_t len_seq) {
  return (strcmp_o(input, _the_seq) < len_seq);
}

inline uint32_t match_ranges(const char_t *input, const Range ranges[], const uint32_t len_ranges) {
  for (uint32_t i = 0; i < len_ranges; i++) {
    if ((ranges[i].left <= input[0] && input[0] <= ranges[i].right)) { return 1U; }
  }
  return 0U;
}

#define tokenize_empty_macro() \
  do {                         \
  } while (0)

#define tokenize_literal_terminal(__type)                                                                          \
  uint32_t t_##__type(const char_t * const input, Terminal *const result, const Allocator * const allocator [[maybe_unused]]) { \
    const char_t * const pattern = TERMINAL_STRINGS[enum_##__type];                                                \
    uint32_t const len = TERMINAL_STRING_LENS[enum_##__type];                                                      \
    if (strcmp_o(input, pattern) == len) {                                                                         \
      result->type = enum_##__type;                                                                                \
      result->value = 0;                                                                                           \
    }                                                                                                              \
    return len;                                                                                                    \
  }

tokenize_literal_terminal(COLON)
tokenize_literal_terminal(COMMA)
tokenize_literal_terminal(EQUAL)
tokenize_literal_terminal(IMMEDIATE)
tokenize_literal_terminal(INSTRUCTION)
tokenize_literal_terminal(LEFT_BRACKET)
tokenize_literal_terminal(MACHINE)
tokenize_literal_terminal(MEMORY)
tokenize_literal_terminal(REGISTER)
tokenize_literal_terminal(RIGHT_BRACKET)
tokenize_literal_terminal(SEMICOLON)
tokenize_literal_terminal(SET)
tokenize_literal_terminal(TYPE)

#define eat_pattern(_pattern_type, ...)            \
  do {                                             \
    len = match_##_pattern_type(_sp, __VA_ARGS__); \
    if (len == 0) { goto __parse_failed; }         \
    _sp += len;                                    \
  } while (0)

#define eat_tokenize(_pattern_type, _body)           \
  do {                                               \
    len = t_##_pattern_type(_sp, result, allocator); \
    if (len == 0) { goto __parse_failed; }           \
    _body _sp += len;                                \
  } while (0)

#define try_pattern(_pattern_type, _try_body, ...) \
  if ((len = match_##_pattern_type(_sp, __VA_ARGS__)) != 0) { _try_body _sp += len; }

#define try_pattern_then(_pattern_type, _try_body, ...)       \
  if ((len = match_##_pattern_type(_sp, __VA_ARGS__)) != 0) { \
    _sp += len;                                               \
    _try_body                                                 \
  }

#define try_tokenize(_pattern_type, _try_body) \
  if ((len = t_##_pattern_type(_sp, result, allocator)) != 0) { _try_body _sp += len; }

#define start_parse(_token_type, _result_type)                                                           \
  uint32_t t_##_token_type(                                                                              \
    const char_t * const input, Terminal *const result, const Allocator * const allocator [[maybe_unused]] \
  ) {                                                                                                    \
    uint32_t len = 0;                                                                                    \
    const char_t *_sp = input;

#define end_parse(_function, _end_body) \
  return _sp - input;                   \
__parse_failed:                         \
  _end_body return 0;                   \
  }

#define tokenize_regular_terminal(_token_type, _parse_body, _if_failed) \
  start_parse(_token_type, Terminal)                                    \
  _parse_body end_parse(_token_type, _if_failed)

tokenize_regular_terminal(
  NUMBER_16,
  {
    uint64_t value = 0;
    do {
      try_pattern(single_range, { value = (value * 16) + _sp[0] - '0'; }, (Range){'0', '9'})
      else try_pattern(single_range, { value = (value * 16) + _sp[0] - 'a'; }, (Range){'a', 'f'})
      else try_pattern(single_range, { value = (value * 16) + _sp[0] - 'A'; }, (Range){'A', 'F'})
      else break;
    } while (len != 0);
    if (_sp - input == 0) { goto __parse_failed; }
    result->value = (void *) value;
  },
  {}
)

tokenize_regular_terminal(
  NUMBER_10,
  {
    uint64_t value = 0;
    do {
      try_pattern(single_range, { value = (value * 10) + _sp[0] - '0'; }, (Range){'0', '9'})
      else break;
    } while (len != 0);
    if (_sp - input == 0) { goto __parse_failed; }
    result->value = (void *) value;
  },
  {}
)

tokenize_regular_terminal(
  NUMBER_2,
  {
    uint64_t value = 0;
    do {
      try_pattern(single_range, { value = (value * 2) + _sp[0] - '0'; }, (Range){'0', '1'})
      else break;
    } while (len != 0);
    if (_sp - input == 0) { goto __parse_failed; }
    result->value = (void *) value;
  },
  {}
)

tokenize_regular_terminal(
  NUMBER,
  {
    try_pattern_then(
      sequence, { eat_tokenize(NUMBER_16, {}); }, "0x", 2
    ) else try_pattern_then(sequence, { eat_tokenize(NUMBER_2, {}); }, "0b", 2) else eat_tokenize(NUMBER_10, {});
    result->type = enum_NUMBER;
  },
  {}
)

typedef struct {
  const char_t *ptr;
  uint32_t len;
} String;

void directly_free(void *_buffer, const Allocator *allocator) {
  return allocator->free(_buffer);
}
constexpr Range RANGE_LETTER_AND_DIGITS[] = {
  {'a', 'z'},
  {'A', 'Z'},
  {'0', '9'}
};
tokenize_regular_terminal(
  IDENTIFIER,
  {
    eat_pattern(ranges, RANGE_LETTER_AND_DIGITS, 2);
    do { try_pattern(ranges, {}, RANGE_LETTER_AND_DIGITS, 3) } while (len != 0);
    result->type = enum_IDENTIFIER;
    result->value = allocator->calloc(1, sizeof(String));
    ((String *) result->value)->ptr = input;
    ((String *) result->value)->len = _sp - input;
  },
  {}
)

tokenize_regular_terminal(
  WIDTH,
  {
    eat_pattern(single_char, char_t('['));
    eat_tokenize(NUMBER_10, { result->value = (void *) (((uint64_t) result->value) & 0xFFFFFFFFULL); });
    try_pattern(
      sequence, { result->value = (void *) (((uint64_t) result->value) | (((uint64_t) WIDTH_BYTE) << 32)); },
      string_t("-byte"), (sizeof "-byte") - 1
    )
    else {
      eat_pattern(sequence, string_t("-bit"), (sizeof "-bit") - 1);
      result->value = (void *) (((uint64_t) result->value) | (((uint64_t) WIDTH_BYTE) << 32));
    }
    eat_pattern(single_char, char_t(']'));
    result->type = enum_WIDTH;
  },
  {}
)

tokenize_regular_terminal(
  TIME_TICK,
  {
    eat_pattern(single_char, char_t('('));
    eat_tokenize(NUMBER_10, { result->value = (void *) (((uint64_t) result->value) & 0xFFFFFFFFULL); });
    eat_pattern(sequence, string_t("-tick"), (sizeof "-tick") - 1);
    eat_pattern(single_char, char_t(')'));
    result->type = enum_TIME_TICK;
  },
  {}
)

tokenize_regular_terminal(
  REG_KEY,
  {
    try_pattern(ranges, {}, RANGE_LETTER_AND_DIGITS, 2)
    else eat_pattern(single_char, '~');
    do {
      try_pattern(ranges, {}, RANGE_LETTER_AND_DIGITS, 3)
      else try_pattern(single_char, {}, '~')
      else break;
    } while (len != 0);
    result->type = enum_REG_KEY;
    result->value = allocator->calloc(1, sizeof(String));
    ((String *) result->value)->ptr = input;
    ((String *) result->value)->len = _sp - input;
  },
  {}
)

typedef struct BitField {
  uint32_t left;
  uint32_t right;
} BitField;
tokenize_regular_terminal(
  BIT_FIELD,
  {
    uint32_t left;
    uint32_t right;

    eat_pattern(single_char, '[');
    eat_tokenize(NUMBER_10, { left = (uint64_t) result->value; });

    eat_pattern(single_char, '-');

    eat_tokenize(NUMBER_10, { right = (uint64_t) result->value; });
    eat_pattern(single_char, ']');

    result->value = allocator->calloc(1, sizeof(BitField));
    ((BitField *) result->value)->left = left;
    ((BitField *) result->value)->right = right;
    result->type = enum_BIT_FIELD;
  },
  {}
)

tokenize_regular_terminal(
  MEM_KEY,
  {
    try_pattern(single_char, { result->value = (void *) MEM_BASE; }, '$')
    else try_pattern(single_char, { result->value = (void *) MEM_BASE; }, '>')
    else {
      goto __parse_failed;
    }
    result->type = enum_MEM_KEY;
  },
  {}
)

tokenize_regular_terminal(
  PART_KEY,
  {
    try_pattern(single_char, { result->value = (void *) PART_PREFIX; }, '^')
    else try_pattern(single_char, { result->value = (void *) PART_SUFFIX; }, '&')
    else try_pattern(single_char, { result->value = (void *) PART_PRINCIPAL; }, '~')
    else {
      goto __parse_failed;
    }
    result->type = enum_PART_KEY;
  },
  {}
)

start_parse(PATTERN, Terminal)
Array *patterns = Array_new(sizeof(String), allocator);

#define append_one_identifier() eat_tokenize(IDENTIFIER, { Array_append(patterns, result->value, 1); })
eat_pattern(single_char, '[');
append_one_identifier();

do {
  try_pattern_then(single_char, { append_one_identifier(); }, ',') else break;
} while (true);

eat_pattern(single_char, ']');
#undef append_one_identifier

result->type = enum_PATTERN;
result->value = patterns;
return _sp - input;
end_parse(PATTERN, {
  Array_reset(patterns, directly_free);
  Array_destroy(patterns);
})

typedef struct {
  uint32_t type;
  void *item;
} EvalItem;

start_parse(EVALUABLE, Terminal)
Array *eval_items = Array_new(sizeof(EvalItem), allocator);
EvalItem item = {};

try_tokenize(NUMBER, {
  item.type = enum_NUMBER;
  item.item = result->value;
  Array_append(eval_items, &item, 1);
}) else {
  eat_tokenize(IDENTIFIER, {
    item.type = enum_IDENTIFIER;
    item.item = result->value;
    Array_append(eval_items, &item, 1);
  });
  do {
    try_pattern_then(
      single_char,
      {
        eat_tokenize(IDENTIFIER, {
          item.type = enum_IDENTIFIER;
          item.item = result->value;
          Array_append(eval_items, &item, 1);
        });
      },
      '.'
    ) else try_tokenize(BIT_FIELD, {
      item.type = enum_BIT_FIELD;
      item.item = result->value;
      Array_append(eval_items, &item, 1);
    }) else {
      break;
    }
  } while (len != 0);
}

result->type = enum_EVALUABLE;
result->value = eval_items;
return _sp - input;
end_parse(EVALUABLE, {
  Array_reset(eval_items, directly_free);
  Array_destroy(eval_items);
})

typedef uint32_t fn_Token(const char_t * const input, Terminal *const result, const Allocator * const allocator);
fn_Token * const t_TERMINATOR = nullptr;

fn_Token *TOKEN_FUNCTIONS[] = {
  [enum_INSTRUCTION] = t_INSTRUCTION,
  [enum_REG_KEY] = t_REG_KEY,
  [enum_IMMEDIATE] = t_IMMEDIATE,
  [enum_COMMA] = t_COMMA,
  [enum_COLON] = t_COLON,
  [enum_MACHINE] = t_MACHINE,
  [enum_SEMICOLON] = t_SEMICOLON,
  [enum_TIME_TICK] = t_TIME_TICK,
  [enum_BIT_FIELD] = t_BIT_FIELD,
  [enum_MEM_KEY] = t_MEM_KEY,
  [enum_PATTERN] = t_PATTERN,
  [enum_SET] = t_SET,
  [enum_EVALUABLE] = t_EVALUABLE,
  [enum_PART_KEY] = t_PART_KEY,
  [enum_WIDTH] = t_WIDTH,
  [enum_LEFT_BRACKET] = t_LEFT_BRACKET,
  [enum_NUMBER] = t_NUMBER,
  [enum_IDENTIFIER] = t_IDENTIFIER,
  [enum_MEMORY] = t_MEMORY,
  [enum_TYPE] = t_TYPE,
  [enum_RIGHT_BRACKET] = t_RIGHT_BRACKET,
  [enum_EQUAL] = t_EQUAL,
  [enum_REGISTER] = t_REGISTER,
  [enum_TERMINATOR] = t_TERMINATOR,
};

Terminal *tokenize(const char_t * const input, uint32_t *cost, uint32_t *n_tokens, const Allocator * const allocator) {
    const char_t *ssp = input;
    uint32_t len = 0;
    while (*ssp) {
        switch (*ssp) {
        }
    }
  return nullptr;
}

inline const char_t *get_name(uint16_t type) {
  return REGEX_TOKEN_NAMES[type];
}
